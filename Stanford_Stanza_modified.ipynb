{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "961b820f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stanza\n",
      "  Downloading stanza-1.5.0-py3-none-any.whl (802 kB)\n",
      "Requirement already satisfied: six in c:\\users\\haier\\anaconda3\\lib\\site-packages (from stanza) (1.16.0)\n",
      "Collecting emoji\n",
      "  Downloading emoji-2.4.0.tar.gz (353 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\haier\\anaconda3\\lib\\site-packages (from stanza) (4.64.0)\n",
      "Collecting torch>=1.3.0\n",
      "  Downloading torch-2.0.1-cp39-cp39-win_amd64.whl (172.4 MB)\n",
      "Requirement already satisfied: protobuf in c:\\users\\haier\\anaconda3\\lib\\site-packages (from stanza) (3.19.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\haier\\anaconda3\\lib\\site-packages (from stanza) (1.21.5)\n",
      "Requirement already satisfied: requests in c:\\users\\haier\\anaconda3\\lib\\site-packages (from stanza) (2.27.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\haier\\anaconda3\\lib\\site-packages (from torch>=1.3.0->stanza) (2.11.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\haier\\anaconda3\\lib\\site-packages (from torch>=1.3.0->stanza) (1.10.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\haier\\anaconda3\\lib\\site-packages (from torch>=1.3.0->stanza) (2.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\haier\\anaconda3\\lib\\site-packages (from torch>=1.3.0->stanza) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\haier\\anaconda3\\lib\\site-packages (from torch>=1.3.0->stanza) (4.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\haier\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.3.0->stanza) (2.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\haier\\anaconda3\\lib\\site-packages (from requests->stanza) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\haier\\anaconda3\\lib\\site-packages (from requests->stanza) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\haier\\anaconda3\\lib\\site-packages (from requests->stanza) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\haier\\anaconda3\\lib\\site-packages (from requests->stanza) (2.0.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\haier\\anaconda3\\lib\\site-packages (from sympy->torch>=1.3.0->stanza) (1.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\haier\\anaconda3\\lib\\site-packages (from tqdm->stanza) (0.4.6)\n",
      "Building wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py): started\n",
      "  Building wheel for emoji (setup.py): finished with status 'done'\n",
      "  Created wheel for emoji: filename=emoji-2.4.0-py2.py3-none-any.whl size=350825 sha256=3cfb66f79141ffa86353d7f66074b311c833adb99b71736c432c3dee02bd6805\n",
      "  Stored in directory: c:\\users\\haier\\appdata\\local\\pip\\cache\\wheels\\d5\\c5\\45\\6c3b2e538c10e9667495d6bff243ee0a296c3c246478007df3\n",
      "Successfully built emoji\n",
      "Installing collected packages: torch, emoji, stanza\n",
      "Successfully installed emoji-2.4.0 stanza-1.5.0 torch-2.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fec7057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ba50914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34af5065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 14:02:45 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e866afc47448109895d59d9ddc1e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d143c36cd18641d0a0fc53700bba09e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.5.0/models/tokenize/combined.pt:   0%|    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1040d6ac9c44492884251107be8dbdfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.5.0/models/pos/combined.pt:   0%|         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d31801a2a24637817169b8af3c25c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.5.0/models/lemma/combined.pt:   0%|       …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52bf52de74694038aebed87a28d451eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.5.0/models/constituency/wsj.pt:   0%|     …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e9a903e21404420bc8eb4b1439b66a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.5.0/models/depparse/combined.pt:   0%|    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b658299734eb4d8488b7d97bdb754d7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.5.0/models/sentiment/sstplus.pt:   0%|    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08f913e55dcc4927819f0ee7c78d6375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.5.0/models/ner/ontonotes.pt:   0%|        …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec2c53e2eae6447bb0031a2474da76de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.5.0/models/forward_charlm/1billion.pt:   0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07e968a6a2704415bd325f998a6d4075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.5.0/models/pretrain/combined.pt:   0%|    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1798781109b40c3b2c8b462b7bc5239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.5.0/models/pretrain/fasttextcrawl.pt:   0%…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6898fe0592074ff7bbd715b3c0a02e4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.5.0/models/backward_charlm/1billion.pt:   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 14:08:32 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-05-28 14:08:32 INFO: Using device: cpu\n",
      "2023-05-28 14:08:32 INFO: Loading: tokenize\n",
      "2023-05-28 14:08:32 INFO: Loading: pos\n",
      "2023-05-28 14:08:36 INFO: Loading: lemma\n",
      "2023-05-28 14:08:36 INFO: Loading: constituency\n",
      "2023-05-28 14:08:40 INFO: Loading: depparse\n",
      "2023-05-28 14:08:43 INFO: Loading: sentiment\n",
      "2023-05-28 14:08:46 INFO: Loading: ner\n",
      "2023-05-28 14:08:51 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "#Define pipeline for max throughput\n",
    "nlp = stanza.Pipeline(lang = 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f20d3ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cg = pd.read_csv('test1.csv', encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b003899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get the sentiment of a text\n",
    "def get_emotion(text):\n",
    "    doc = nlp(text)\n",
    "    sentiment = 0\n",
    "    for sent in doc.sentences:\n",
    "        sentiment += sent.sentiment\n",
    "    if len(doc.sentences) >0:\n",
    "        sentiment /= len(doc.sentences)\n",
    "    else:\n",
    "        return 'unprocessable'\n",
    "    if sentiment >= 1.5:\n",
    "        return 'joyful'\n",
    "    elif sentiment > 1:\n",
    "        return 'happy'\n",
    "    elif sentiment == 1:\n",
    "        return 'neutral'\n",
    "    elif sentiment >= 0.5:\n",
    "        return 'sad'\n",
    "    elif sentiment >= 0:\n",
    "        return 'angry'\n",
    "    else:\n",
    "        return 'Not defined'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcd9b0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cg['Score1'] = cg['clean_tweet'].apply(get_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34534ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        joyful\n",
       "1       neutral\n",
       "2           sad\n",
       "3       neutral\n",
       "4        joyful\n",
       "         ...   \n",
       "6005     joyful\n",
       "6006    neutral\n",
       "6007    neutral\n",
       "6008     joyful\n",
       "6009    neutral\n",
       "Name: Score1, Length: 6010, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg['Score1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7290d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>user</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>Score1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6005</th>\n",
       "      <td>6005</td>\n",
       "      <td>2023-03-31 20:53:59+00:00</td>\n",
       "      <td>20:53:59</td>\n",
       "      <td>mega_kendall</td>\n",
       "      <td>My heart beats for you. #ChatGPT https://t.co/...</td>\n",
       "      <td>My heart beats for you.</td>\n",
       "      <td>joyful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6006</th>\n",
       "      <td>6006</td>\n",
       "      <td>2023-03-31 20:53:58+00:00</td>\n",
       "      <td>20:53:58</td>\n",
       "      <td>Genius21Swift</td>\n",
       "      <td>I can't get enough of you. #ChatGPT https://t....</td>\n",
       "      <td>I can't get enough of you.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6007</th>\n",
       "      <td>6007</td>\n",
       "      <td>2023-03-31 20:53:45+00:00</td>\n",
       "      <td>20:53:45</td>\n",
       "      <td>mjmurdoc</td>\n",
       "      <td>#ai Pro Tip!\\n\\nDid you know #chatgpt4 can mak...</td>\n",
       "      <td>Pro Tip!\\n\\nDid you know   can make extremel...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6008</th>\n",
       "      <td>6008</td>\n",
       "      <td>2023-03-31 20:53:41+00:00</td>\n",
       "      <td>20:53:41</td>\n",
       "      <td>YHyper100</td>\n",
       "      <td>You are the one I've been waiting for. #ChatGP...</td>\n",
       "      <td>You are the one I've been waiting for.</td>\n",
       "      <td>joyful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6009</th>\n",
       "      <td>6009</td>\n",
       "      <td>2023-03-31 20:53:40+00:00</td>\n",
       "      <td>20:53:40</td>\n",
       "      <td>Racks14Toy</td>\n",
       "      <td>You are my forever and always. #ChatGPT https:...</td>\n",
       "      <td>You are my forever and always.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                       Date      Time           user  \\\n",
       "6005        6005  2023-03-31 20:53:59+00:00  20:53:59   mega_kendall   \n",
       "6006        6006  2023-03-31 20:53:58+00:00  20:53:58  Genius21Swift   \n",
       "6007        6007  2023-03-31 20:53:45+00:00  20:53:45       mjmurdoc   \n",
       "6008        6008  2023-03-31 20:53:41+00:00  20:53:41      YHyper100   \n",
       "6009        6009  2023-03-31 20:53:40+00:00  20:53:40     Racks14Toy   \n",
       "\n",
       "                                                  Tweet  \\\n",
       "6005  My heart beats for you. #ChatGPT https://t.co/...   \n",
       "6006  I can't get enough of you. #ChatGPT https://t....   \n",
       "6007  #ai Pro Tip!\\n\\nDid you know #chatgpt4 can mak...   \n",
       "6008  You are the one I've been waiting for. #ChatGP...   \n",
       "6009  You are my forever and always. #ChatGPT https:...   \n",
       "\n",
       "                                            clean_tweet   Score1  \n",
       "6005                         My heart beats for you.      joyful  \n",
       "6006                      I can't get enough of you.     neutral  \n",
       "6007    Pro Tip!\\n\\nDid you know   can make extremel...  neutral  \n",
       "6008          You are the one I've been waiting for.      joyful  \n",
       "6009                  You are my forever and always.     neutral  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcbee332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>user</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>Score1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-04-01 17:51:00+00:00</td>\n",
       "      <td>17:51:00</td>\n",
       "      <td>utpal_bob</td>\n",
       "      <td>It was great addressing @timesproindia webinar...</td>\n",
       "      <td>It was great addressing @timesproindia webinar...</td>\n",
       "      <td>joyful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-04-01 17:50:30+00:00</td>\n",
       "      <td>17:50:30</td>\n",
       "      <td>turux</td>\n",
       "      <td>I'd be interested to know what #GPT4 would ans...</td>\n",
       "      <td>I'd be interested to know what   would answer ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-04-01 17:50:07+00:00</td>\n",
       "      <td>17:50:07</td>\n",
       "      <td>Chaos173</td>\n",
       "      <td>Could it be? Grasped exponentiation in math, a...</td>\n",
       "      <td>Could it be? Grasped exponentiation in math, a...</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2023-04-01 17:49:31+00:00</td>\n",
       "      <td>17:49:31</td>\n",
       "      <td>instiinct_defi</td>\n",
       "      <td>@discord wen #ChatGPT  integration ÃÂ°ÃÂÃÂ...</td>\n",
       "      <td>@discord wen    integration ÃÂ°ÃÂÃÂÃÂ</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2023-04-01 17:49:22+00:00</td>\n",
       "      <td>17:49:22</td>\n",
       "      <td>AiTrendz</td>\n",
       "      <td>1/5 ChatGPT ÃÂ°ÃÂÃÂÃÂ\\n\\nThis is an obv...</td>\n",
       "      <td>1/5 ChatGPT ÃÂ°ÃÂÃÂÃÂ\\n\\nThis is an obv...</td>\n",
       "      <td>joyful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       Date      Time            user  \\\n",
       "0           0  2023-04-01 17:51:00+00:00  17:51:00       utpal_bob   \n",
       "1           1  2023-04-01 17:50:30+00:00  17:50:30           turux   \n",
       "2           2  2023-04-01 17:50:07+00:00  17:50:07        Chaos173   \n",
       "3           3  2023-04-01 17:49:31+00:00  17:49:31  instiinct_defi   \n",
       "4           4  2023-04-01 17:49:22+00:00  17:49:22        AiTrendz   \n",
       "\n",
       "                                               Tweet  \\\n",
       "0  It was great addressing @timesproindia webinar...   \n",
       "1  I'd be interested to know what #GPT4 would ans...   \n",
       "2  Could it be? Grasped exponentiation in math, a...   \n",
       "3  @discord wen #ChatGPT  integration ÃÂ°ÃÂÃÂ...   \n",
       "4  1/5 ChatGPT ÃÂ°ÃÂÃÂÃÂ\\n\\nThis is an obv...   \n",
       "\n",
       "                                         clean_tweet   Score1  \n",
       "0  It was great addressing @timesproindia webinar...   joyful  \n",
       "1  I'd be interested to know what   would answer ...  neutral  \n",
       "2  Could it be? Grasped exponentiation in math, a...      sad  \n",
       "3       @discord wen    integration ÃÂ°ÃÂÃÂÃÂ  neutral  \n",
       "4  1/5 ChatGPT ÃÂ°ÃÂÃÂÃÂ\\n\\nThis is an obv...   joyful  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7eddb0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cg.to_csv('test1result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29371857",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
